#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∫ Directus
–ß–∏—Ç–∞–µ—Ç SQL —Ñ–∞–π–ª—ã –º–∏–≥—Ä–∞—Ü–∏–π –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ Directus
"""

import re
import os
import requests
import json
from typing import List, Dict, Any, Optional
from pathlib import Path

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Directus API
API_URL = "https://api.studsovet.kosygin-rsu.ru"
TOKEN = "Z--i8pfKr19Y445ZRTbjKfnYVbVCQFN1"

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–∏–≥—Ä–∞—Ü–∏—è–º–∏
MIGRATIONS_DIR = Path(__file__).parent

headers = {
    "Authorization": f"Bearer {TOKEN}",
    "Content-Type": "application/json"
}

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö SQL -> Directus
SQL_TO_DIRECTUS_TYPE_MAPPING = {
    'VARCHAR': 'string',
    'TEXT': 'text',
    'BOOLEAN': 'boolean',
    'INTEGER': 'integer',
    'SERIAL': 'integer',
    'TIMESTAMP': 'timestamp',
    'JSONB': 'json'
}

class DirectusMigrationError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–æ–∫ –º–∏–≥—Ä–∞—Ü–∏–∏"""
    pass

class MigrationParser:
    """–ü–∞—Ä—Å–µ—Ä SQL –º–∏–≥—Ä–∞—Ü–∏–π"""
    
    def __init__(self):
        self.alter_statements = []
        self.create_index_statements = []
    
    def parse_migration_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –º–∏–≥—Ä–∞—Ü–∏–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        operations = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        content = re.sub(r'--.*$', '', content, flags=re.MULTILINE)
        
        # –ò—â–µ–º CREATE TABLE statements –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π
        create_table_pattern = r'CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(\w+)\s*\((.*?)\);'
        create_tables = re.findall(create_table_pattern, content, re.DOTALL | re.IGNORECASE)
        
        for table_name, table_definition in create_tables:
            # –ü–∞—Ä—Å–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª–µ–π –≤ CREATE TABLE
            field_pattern = r'(\w+)\s+(\w+(?:\([^)]*\))?)\s*(?:NOT\s+NULL|DEFAULT[^,]*)?(?:\s+REFERENCES\s+[^\s)]+)?(?:\s+ON\s+DELETE\s+\w+)?(?:\s+ON\s+UPDATE\s+\w+)?(?:,|\s*$)'
            fields = re.findall(field_pattern, table_definition, re.IGNORECASE)
            
            for field_name, data_type in fields:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è
                if field_name.upper() in ['SERIAL', 'PRIMARY', 'CONSTRAINT', 'INDEX', 'KEY']:
                    continue
                    
                operations.append({
                    'type': 'add_column',
                    'table': table_name.lower(),
                    'column': field_name.lower(),
                    'data_type': data_type.strip(),
                    'file': file_path.name,
                    'source': 'create_table'
                })
        
        # –ò—â–µ–º ALTER TABLE statements
        alter_pattern = r'ALTER\s+TABLE\s+(\w+)\s+ADD\s+COLUMN\s+(?:IF\s+NOT\s+EXISTS\s+)?(\w+)\s+([^;]+);'
        alters = re.findall(alter_pattern, content, re.IGNORECASE)
        
        for table, column, data_type in alters:
            operations.append({
                'type': 'add_column',
                'table': table.lower(),
                'column': column.lower(),
                'data_type': data_type.strip(),
                'file': file_path.name,
                'source': 'alter_table'
            })
        
        # –ò—â–µ–º CREATE INDEX statements
        index_pattern = r'CREATE\s+(?:UNIQUE\s+)?INDEX\s+(?:IF\s+NOT\s+EXISTS\s+)?(\w+)\s+ON\s+(\w+)\s*\(([^)]+)\);'
        indexes = re.findall(index_pattern, content, re.IGNORECASE)
        
        for index_name, table, columns in indexes:
            operations.append({
                'type': 'create_index',
                'table': table.lower(),
                'index_name': index_name.lower(),
                'columns': [col.strip() for col in columns.split(',')],
                'file': file_path.name,
                'source': 'create_index'
            })
        
        # –ò—â–µ–º INSERT statements (–ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö)
        insert_pattern = r'INSERT\s+INTO\s+(\w+)\s*\(([^)]+)\)\s*VALUES\s*\(([^)]+)\);'
        inserts = re.findall(insert_pattern, content, re.IGNORECASE)
        
        for table, columns, values in inserts:
            # –ü–∞—Ä—Å–∏–º –∫–æ–ª–æ–Ω–∫–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è
            columns_list = [col.strip() for col in columns.split(',')]
            values_list = self._parse_values(values)
            
            if len(columns_list) == len(values_list):
                data = dict(zip(columns_list, values_list))
                operations.append({
                    'type': 'insert_data',
                    'table': table.lower(),
                    'data': data,
                    'file': file_path.name,
                    'source': 'insert_data'
                })
        
        return operations
    
    def _parse_values(self, values_str: str) -> List[Any]:
        """–ü–∞—Ä—Å–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ SQL INSERT"""
        values = []
        current_value = ""
        in_quotes = False
        escape_next = False
        
        for char in values_str.strip():
            if escape_next:
                current_value += char
                escape_next = False
                continue
                
            if char == '\\':
                escape_next = True
                continue
                
            if char == "'":
                in_quotes = not in_quotes
                continue
                
            if char == ',' and not in_quotes:
                values.append(current_value.strip())
                current_value = ""
            else:
                current_value += char
        
        if current_value.strip():
            values.append(current_value.strip())
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
        parsed_values = []
        for val in values:
            if val.upper() == 'NULL':
                parsed_values.append(None)
            elif val.upper() == 'TRUE':
                parsed_values.append(True)
            elif val.upper() == 'FALSE':
                parsed_values.append(False)
            elif val.startswith('[') and val.endswith(']'):
                # JSON array
                try:
                    parsed_values.append(json.loads(val.replace("'", '"')))
                except:
                    parsed_values.append(val)
            else:
                try:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∫–∞–∫ —á–∏—Å–ª–æ
                    if '.' in val:
                        parsed_values.append(float(val))
                    else:
                        parsed_values.append(int(val))
                except ValueError:
                    # –°—Ç—Ä–æ–∫–∞
                    parsed_values.append(val)
        
        return parsed_values

class DirectusFieldManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª—è–º–∏ Directus"""
    
    def __init__(self, api_url: str, headers: Dict[str, str]):
        self.api_url = api_url.rstrip('/')
        self.headers = headers
    
    def create_field(self, collection: str, field_name: str, field_config: Dict[str, Any]) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–µ –≤ Directus –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        url = f"{self.api_url}/fields/{collection}"
        
        payload = {
            "field": field_name,
            **field_config
        }
        
        try:
            response = requests.post(url, headers=self.headers, json=payload)
            if response.status_code in (200, 201):
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø–æ–ª–µ '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}'")
                return True
            elif response.status_code == 409:
                print(f"‚ö†Ô∏è  –ü–æ–ª–µ '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                return True
            elif response.status_code == 400:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—à–∏–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –ø–æ–ª–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                try:
                    error_data = response.json()
                    if "already exists" in error_data.get("errors", [{}])[0].get("message", "").lower():
                        print(f"‚ö†Ô∏è  –ü–æ–ª–µ '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                        return True
                except:
                    pass
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—è '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}': {response.status_code} {response.text}")
                return False
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª—è '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}': {response.status_code} {response.text}")
                return False
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–æ–ª—è '{field_name}' –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}': {e}")
            return False
    
    def create_record(self, collection: str, data: Dict[str, Any]) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ Directus –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        url = f"{self.api_url}/items/{collection}"
        
        payload = {"data": data}
        
        try:
            response = requests.post(url, headers=self.headers, json=payload)
            if response.status_code in (200, 201):
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∑–∞–ø–∏—Å—å –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}'")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}': {response.status_code} {response.text}")
                return False
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–ø–∏—Å–∏ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection}': {e}")
            return False

def sql_type_to_directus_config(sql_type: str) -> Dict[str, Any]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç SQL —Ç–∏–ø –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Directus –ø–æ–ª—è"""
    sql_type_upper = sql_type.upper().strip()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    match = re.match(r'(\w+)(\([^)]*\))?', sql_type_upper)
    if not match:
        return {"type": "string"}
    
    base_type = match.group(1)
    
    # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É
    if base_type in SQL_TO_DIRECTUS_TYPE_MAPPING:
        directus_type = SQL_TO_DIRECTUS_TYPE_MAPPING[base_type]
        
        config = {"type": directus_type}
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Ç–∏–ø–æ–≤
        if base_type == 'VARCHAR' or base_type == 'TEXT':
            config["meta"] = {"interface": "input"}
        elif base_type == 'BOOLEAN':
            config["meta"] = {"interface": "boolean"}
        elif base_type == 'TIMESTAMP':
            config["meta"] = {"interface": "datetime"}
        elif base_type == 'JSONB':
            config["meta"] = {"interface": "code"}
            config["type"] = "json"
        
        return config
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Å—Ç—Ä–æ–∫–∞
    return {"type": "string", "meta": {"interface": "input"}}

def apply_migrations():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–∏–≥—Ä–∞—Ü–∏–π"""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π –∫ Directus...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä Directus
    field_manager = DirectusFieldManager(API_URL, headers)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä
    parser = MigrationParser()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –º–∏–≥—Ä–∞—Ü–∏–π –≤ –ø–æ—Ä—è–¥–∫–µ
    migration_files = sorted(MIGRATIONS_DIR.glob("*.sql"))
    
    if not migration_files:
        print("‚ùå –§–∞–π–ª—ã –º–∏–≥—Ä–∞—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
        return
    
    all_operations = []
    
    # –ü–∞—Ä—Å–∏–º –≤—Å–µ –º–∏–≥—Ä–∞—Ü–∏–∏
    for migration_file in migration_files:
        print(f"üìÑ –ß–∏—Ç–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é: {migration_file.name}")
        operations = parser.parse_migration_file(migration_file)
        all_operations.extend(operations)
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(all_operations)} –æ–ø–µ—Ä–∞—Ü–∏–π –≤ {len(migration_files)} —Ñ–∞–π–ª–∞—Ö")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏
    success_count = 0
    error_count = 0
    
    for operation in all_operations:
        print(f"\nüîß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é: {operation['type']} - {operation.get('table', 'N/A')} ({operation['file']})")
        
        if operation['type'] == 'add_column':
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–µ –≤ Directus
            directus_config = sql_type_to_directus_config(operation['data_type'])
            directus_config['schema'] = {"name": operation['column']}
            
            if field_manager.create_field(operation['table'], operation['column'], directus_config):
                success_count += 1
            else:
                error_count += 1
        
        elif operation['type'] == 'insert_data':
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å –¥–∞–Ω–Ω—ã–º–∏
            if field_manager.create_record(operation['table'], operation['data']):
                success_count += 1
            else:
                error_count += 1
        
        elif operation['type'] == 'create_index':
            # –ò–Ω–¥–µ–∫—Å—ã –≤ Directus —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            print(f"‚ÑπÔ∏è  –ò–Ω–¥–µ–∫—Å {operation['index_name']} –≤ —Ç–∞–±–ª–∏—Ü–µ {operation['table']} –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            success_count += 1
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüìà –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç:")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {success_count}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {error_count}")
    print(f"üìä –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {success_count + error_count}")
    
    if error_count == 0:
        print("\nüéâ –í—Å–µ –º–∏–≥—Ä–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!")
    else:
        print(f"\n‚ö†Ô∏è  –ü—Ä–∏–º–µ–Ω–µ–Ω–æ {success_count} –æ–ø–µ—Ä–∞—Ü–∏–π, {error_count} —Å –æ—à–∏–±–∫–∞–º–∏")

if __name__ == "__main__":
    try:
        apply_migrations()
    except KeyboardInterrupt:
        print("\n\n‚õî –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise